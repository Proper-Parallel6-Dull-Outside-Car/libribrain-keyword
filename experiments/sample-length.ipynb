{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784ed89f-ebb0-4a0d-8030-ba2443b4e7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "%pip install -q mne_bids lightning torchmetrics scikit-learn plotly ipywidgets neptune\n",
    "\n",
    "# Set up base path for dataset and related files\n",
    "base_path = \"./libribrain\"\n",
    "\n",
    "# Install pnpl from local modified package\n",
    "%pip install ../modified-pnpl/pnpl\n",
    "\n",
    "# Remember to set the NEPTUNE_API_TOKEN and NEPTUNE_PROJECT environment variables\n",
    "# before running the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80d766e-9c77-4660-beef-1fd14785b48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Watson keyword detection on LibriBrain (MEG)\n",
    "- Oversampling-only training (no class-weighting)\n",
    "- Focal loss + pairwise ranking aux loss\n",
    "- Temporal attention pooling backbone\n",
    "- Robust, PR-friendly validation/test diagnostics\n",
    "- Warmup + cosine LR; optional Neptune logging\n",
    "- Fast cached label indexing for balanced sampler\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import os, math, random, json, hashlib, csv\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple, List, Iterator\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, BatchSampler\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor, EarlyStopping\n",
    "\n",
    "# ----------------- Utilities -----------------\n",
    "def collate_label_only_xy(batch):  # picklable; used by index scan\n",
    "    return [int(y) for _, y in batch]\n",
    "\n",
    "def _cpu(t): return t.detach().float().cpu()\n",
    "\n",
    "# ---------------- Neptune (optional) ----------------\n",
    "def make_neptune_logger(run_name: str | None = None):\n",
    "    api_key, project = os.getenv(\"NEPTUNE_API_TOKEN\"), os.getenv(\"NEPTUNE_PROJECT\")\n",
    "    if not api_key or not project:\n",
    "        print(\"Neptune: env vars not found -> skipping Neptune logging.\")\n",
    "        return None\n",
    "    try:\n",
    "        from lightning.pytorch.loggers import NeptuneLogger as _BaseNeptuneLogger\n",
    "    except Exception:\n",
    "        from pytorch_lightning.loggers import NeptuneLogger as _BaseNeptuneLogger\n",
    "\n",
    "    class CleanNeptuneLogger(_BaseNeptuneLogger):\n",
    "        def log_metrics(self, metrics, step: int | None = None):\n",
    "            filt = {k: v for k, v in metrics.items() if k != \"epoch\" and not k.endswith(\"/epoch\")}\n",
    "            super().log_metrics(filt, step=None)\n",
    "\n",
    "    logger = CleanNeptuneLogger(\n",
    "        api_key=api_key, project=project, name=run_name,\n",
    "        tags=[\"libribrain\", \"watson\", \"meg\", \"keyword-detection\"],\n",
    "        prefix=\"training/\", log_model_checkpoints=False,\n",
    "    )\n",
    "    print(\"Neptune: ✅ enabled.\")\n",
    "    return logger\n",
    "\n",
    "# ---------------- Model ----------------\n",
    "class ResNetBlock1D(nn.Module):\n",
    "    def __init__(self, channels: int = 128):\n",
    "        super().__init__()\n",
    "        same_supported = 'same' in nn.Conv1d.__init__.__code__.co_varnames\n",
    "        pad3 = 'same' if same_supported else 1\n",
    "        self.net = nn.Sequential(\n",
    "            nn.ELU(), nn.Conv1d(channels, channels, 3, 1, pad3),\n",
    "            nn.ELU(), nn.Conv1d(channels, channels, 1, 1, 0),\n",
    "        )\n",
    "    def forward(self, x): return x + self.net(x)\n",
    "\n",
    "class SpeechDetectionNet(nn.Module):\n",
    "    \"\"\"Conv trunk + temporal attention pooling.\"\"\"\n",
    "    def __init__(self, in_channels: int = 306, lse_temperature: float = 0.5):  # lse_temperature kept for API compat\n",
    "        super().__init__()\n",
    "        same_supported = 'same' in nn.Conv1d.__init__.__code__.co_varnames\n",
    "        pad7 = 'same' if same_supported else 3\n",
    "        self.trunk = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, 128, 7, 1, pad7),\n",
    "            ResNetBlock1D(128),\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(128, 128, 50, 25, 0),  # downsample time\n",
    "            nn.ELU(),\n",
    "            nn.Conv1d(128, 128, 7, 1, pad7),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "        self.head = nn.Sequential(nn.Conv1d(128, 512, 4, 1, 0), nn.ReLU(), nn.Dropout(0.5))\n",
    "        self.logits_t = nn.Conv1d(512, 1, 1, 1, 0)\n",
    "        self.attn_t   = nn.Conv1d(512, 1, 1, 1, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.head(self.trunk(x))        # (N,512,T')\n",
    "        logit_t = self.logits_t(h)          # (N,1,T')\n",
    "        attn = torch.softmax(self.attn_t(h), dim=-1)\n",
    "        return (logit_t * attn).sum(dim=-1).squeeze(1)  # (N,)\n",
    "\n",
    "# ---------------- Losses + metrics helpers ----------------\n",
    "@dataclass\n",
    "class OptimConfig:\n",
    "    lr: float = 1e-4\n",
    "    weight_decay: float = 1e-4\n",
    "    max_time_shift: int = 4\n",
    "    noise_std: float = 0.01\n",
    "    warmup_epochs: int = 1\n",
    "    cosine_after_warmup: bool = True\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha: float = 0.95, gamma: float = 2.0):\n",
    "        super().__init__(); self.alpha = float(alpha); self.gamma = float(gamma)\n",
    "    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        ce = nn.functional.binary_cross_entropy_with_logits(logits, targets.float(), reduction='none')\n",
    "        p = torch.sigmoid(logits); pt = torch.where(targets == 1, p, 1 - p)\n",
    "        alpha_t = torch.where(targets == 1, logits.new_tensor(self.alpha), logits.new_tensor(1 - self.alpha))\n",
    "        return (alpha_t * (1 - pt).pow(self.gamma) * ce).mean()\n",
    "\n",
    "try:\n",
    "    from torchmetrics.classification import BinaryAccuracy, BinaryAveragePrecision, BinaryAUROC\n",
    "except Exception:\n",
    "    from torchmetrics import Accuracy as BinaryAccuracy                 # type: ignore\n",
    "    from torchmetrics import AveragePrecision as BinaryAveragePrecision # type: ignore\n",
    "    from torchmetrics import AUROC as BinaryAUROC                       # type: ignore\n",
    "\n",
    "# ---------------- LightningModule ----------------\n",
    "class WatsonKeywordPL(pl.LightningModule):\n",
    "    def __init__(self, in_channels: int = 306, pos_weight: float = 1.0,\n",
    "                 opt: OptimConfig = OptimConfig(), lse_temperature: float = 0.5,\n",
    "                 pairwise_lambda: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = SpeechDetectionNet(in_channels, lse_temperature=lse_temperature)\n",
    "        self.register_buffer(\"pos_weight_tensor\", torch.tensor([pos_weight], dtype=torch.float32))  # kept for API compat\n",
    "        self.criterion = FocalLoss(alpha=0.95, gamma=2.0)\n",
    "        self.pairwise_lambda = float(pairwise_lambda)\n",
    "\n",
    "        # epoch aggregates (ranking-friendly)\n",
    "        self.train_acc = BinaryAccuracy(); self.val_acc = BinaryAccuracy(); self.test_acc = BinaryAccuracy()\n",
    "        self.val_auprc = BinaryAveragePrecision(); self.test_auprc = BinaryAveragePrecision()\n",
    "        self.val_auroc = BinaryAUROC(); self.test_auroc = BinaryAUROC()\n",
    "\n",
    "        self._val_probs: List[torch.Tensor] = []; self._val_labels: List[torch.Tensor] = []\n",
    "        self._test_probs: List[torch.Tensor] = []; self._test_labels: List[torch.Tensor] = []\n",
    "        self._train_pos = 0; self._train_total = 0\n",
    "        self._val_pos = 0; self._val_total = 0\n",
    "\n",
    "    # ---- small helpers ----\n",
    "    @staticmethod\n",
    "    def _pairwise_logistic_loss(logits: torch.Tensor, labels: torch.Tensor, max_pairs: int = 4096) -> torch.Tensor:\n",
    "        pos_idx = (labels == 1).nonzero(as_tuple=False).view(-1)\n",
    "        neg_idx = (labels == 0).nonzero(as_tuple=False).view(-1)\n",
    "        if pos_idx.numel() == 0 or neg_idx.numel() == 0: return logits.new_zeros(())\n",
    "        num_pairs = min(max_pairs, int(pos_idx.numel()) * int(neg_idx.numel()))\n",
    "        pi = pos_idx[torch.randint(0, pos_idx.numel(), (num_pairs,), device=logits.device)]\n",
    "        ni = neg_idx[torch.randint(0, neg_idx.numel(), (num_pairs,), device=logits.device)]\n",
    "        return torch.nn.functional.softplus(-(logits[pi] - logits[ni])).mean()\n",
    "\n",
    "    @staticmethod\n",
    "    def _rprecision(probs: torch.Tensor, labels: torch.Tensor) -> float:\n",
    "        m = int(labels.sum().item()); \n",
    "        if m <= 0: return 0.0\n",
    "        k = min(m, probs.numel())\n",
    "        prec_at_m = labels[torch.topk(probs, k=k, largest=True).indices].float().mean().item()\n",
    "        return float(prec_at_m)\n",
    "\n",
    "    @staticmethod\n",
    "    def _precision_recall_at_k(probs: torch.Tensor, labels: torch.Tensor, k: int) -> Tuple[float, float]:\n",
    "        k = max(1, min(k, probs.numel()))\n",
    "        topk = torch.topk(probs, k=k, largest=True).indices\n",
    "        tp = labels[topk].sum().item()\n",
    "        prec = tp / k; rec = tp / max(1, int(labels.sum().item()))\n",
    "        return float(prec), float(rec)\n",
    "\n",
    "    @staticmethod\n",
    "    def _best_f1(probs: torch.Tensor, labels: torch.Tensor) -> Tuple[float, float, Tuple[int,int,int,int]]:\n",
    "        N = probs.numel()\n",
    "        if N == 0: return 0.0, 0.5, (0,0,0,0)\n",
    "        sort_idx = torch.argsort(probs, descending=True); y = labels[sort_idx].to(torch.int32)\n",
    "        cum_tp = torch.cumsum(y, dim=0); ks = torch.arange(1, N+1, device=probs.device)\n",
    "        precision = cum_tp / ks; total_pos = max(1, int(labels.sum().item()))\n",
    "        recall = cum_tp / total_pos\n",
    "        denom = precision + recall\n",
    "        f1 = torch.where(denom > 0, 2 * precision * recall / denom, torch.zeros_like(denom))\n",
    "        i = int(torch.argmax(f1).item()); best_f1 = float(f1[i].item()); thr = float(probs[sort_idx[i]].item())\n",
    "        k = i + 1; tp = int(cum_tp[i].item()); fp = int(k - tp); fn = int(total_pos - tp); tn = int(N - k - fn)\n",
    "        return best_f1, thr, (tp, fp, tn, fn)\n",
    "\n",
    "    @staticmethod\n",
    "    def _f1_macro_at_threshold(probs: torch.Tensor, labels: torch.Tensor, threshold: float = 0.5) -> float:\n",
    "        if probs.numel() == 0: return 0.0\n",
    "        preds, lab = (probs >= threshold).to(torch.int32), labels.to(torch.int32)\n",
    "        tp = int(((preds == 1) & (lab == 1)).sum().item())\n",
    "        fp = int(((preds == 1) & (lab == 0)).sum().item())\n",
    "        fn = int(((preds == 0) & (lab == 1)).sum().item())\n",
    "        tn = int(((preds == 0) & (lab == 0)).sum().item())\n",
    "        def _f1(p, r): return 0.0 if (p + r) == 0 else (2 * p * r) / (p + r)\n",
    "        prec_pos = tp / max(1, tp + fp); rec_pos = tp / max(1, tp + fn)\n",
    "        prec_neg = tn / max(1, tn + fn); rec_neg = tn / max(1, tn + fp)\n",
    "        return float((_f1(prec_pos, rec_pos) + _f1(prec_neg, rec_neg)) / 2.0)\n",
    "\n",
    "    @staticmethod\n",
    "    def _recall_at_precision(probs: torch.Tensor, labels: torch.Tensor, min_precision: float = 0.9) -> float:\n",
    "        N = probs.numel()\n",
    "        if N == 0: return 0.0\n",
    "        sort_idx = torch.argsort(probs, descending=True); y = labels[sort_idx].to(torch.int32)\n",
    "        cum_tp = torch.cumsum(y, dim=0); ks = torch.arange(1, N+1, device=probs.device)\n",
    "        precision = cum_tp / ks; total_pos = max(1, int(labels.sum().item()))\n",
    "        recall = cum_tp / total_pos\n",
    "        mask = precision >= min_precision\n",
    "        return float(recall[mask].max().item()) if mask.any() else 0.0\n",
    "\n",
    "    # ---- Lightning required ----\n",
    "    def forward(self, x): return self.model(x)\n",
    "\n",
    "    def _augment(self, x):\n",
    "        if not self.training: return x\n",
    "        smax = self.hparams.opt.max_time_shift\n",
    "        if smax and smax > 0:\n",
    "            shifts = torch.randint(-smax, smax + 1, (x.size(0),), device=x.device)\n",
    "            for i, sh in enumerate(shifts):\n",
    "                if int(sh) != 0: x[i] = torch.roll(x[i], int(sh), dims=-1)\n",
    "        sigma = self.hparams.opt.noise_std\n",
    "        return x + torch.randn_like(x) * sigma if (sigma and sigma > 0) else x\n",
    "\n",
    "    def _bce_unweighted(self, logits, y):\n",
    "        return nn.functional.binary_cross_entropy_with_logits(logits.float(), y.float())\n",
    "\n",
    "    def training_step(self, batch, _):\n",
    "        x, y = batch\n",
    "        self._train_pos += int(y.sum()); self._train_total += int(y.numel())\n",
    "        logits = self(self._augment(x))\n",
    "        focal = self.criterion(logits.float(), y.float())\n",
    "        pairwise = self._pairwise_logistic_loss(logits.detach(), y)  # detached for stability\n",
    "        loss = focal + self.pairwise_lambda * pairwise\n",
    "        probs = torch.sigmoid(logits.float())\n",
    "        self.train_acc.update(probs, y)\n",
    "        self.log_dict({\n",
    "            \"train_loss\": loss, \"train_focal\": focal, \"train_pairwise\": pairwise,\n",
    "            \"train_pos_frac\": y.float().mean(),\n",
    "        }, on_step=True, on_epoch=True, prog_bar=False)\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self.log(\"train_acc\", self.train_acc.compute(), on_step=False, on_epoch=True, prog_bar=True)\n",
    "        if self._train_total > 0:\n",
    "            self.log(\"train_pos_fraction_epoch\", float(self._train_pos) / float(self._train_total),\n",
    "                     on_step=False, on_epoch=True)\n",
    "        self._train_pos = 0; self._train_total = 0; self.train_acc.reset()\n",
    "\n",
    "    def on_validation_epoch_start(self):\n",
    "        self._val_pos = 0; self._val_total = 0; self._val_probs.clear(); self._val_labels.clear()\n",
    "\n",
    "    def validation_step(self, batch, _):\n",
    "        x, y = batch\n",
    "        logits = self(x); probs = torch.sigmoid(logits.float())\n",
    "        self.val_acc.update(probs, y); self.val_auprc.update(probs, y); self.val_auroc.update(probs, y)\n",
    "        self._val_pos += int(y.sum()); self._val_total += int(y.numel())\n",
    "        self._val_probs.append(_cpu(probs)); self._val_labels.append(_cpu(y).int())\n",
    "        self.log(\"val_loss\", self._bce_unweighted(logits, y), on_step=False, on_epoch=True)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        base_rate = (self._val_pos / max(self._val_total, 1)) if self._val_total > 0 else 0.0\n",
    "        both_classes = (self._val_pos > 0) and (self._val_pos < self._val_total)\n",
    "        val_acc = self.val_acc.compute()\n",
    "        val_auprc = (self.val_auprc.compute() if self._val_pos > 0\n",
    "                     else torch.as_tensor(base_rate, device=self.device))\n",
    "        val_auroc = (self.val_auroc.compute() if both_classes\n",
    "                     else torch.as_tensor(0.5, device=self.device))\n",
    "\n",
    "        probs = torch.cat(self._val_probs, dim=0) if self._val_probs else torch.empty(0)\n",
    "        labels = torch.cat(self._val_labels, dim=0) if self._val_labels else torch.empty(0, dtype=torch.int64)\n",
    "        if probs.numel() != labels.numel(): probs = probs[:labels.numel()]\n",
    "\n",
    "        rprec = self._rprecision(probs, labels)\n",
    "        m = int(labels.sum().item()) if labels.numel() > 0 else 1\n",
    "        prec_m, rec_m = self._precision_recall_at_k(probs, labels, max(1, m))\n",
    "        prec_2m, rec_2m = self._precision_recall_at_k(probs, labels, max(1, 2*m))\n",
    "        prec_5m, rec_5m = self._precision_recall_at_k(probs, labels, max(1, 5*m))\n",
    "        best_f1, best_thr, (tp, fp, tn, fn) = self._best_f1(probs, labels)\n",
    "        rec_at_p90 = self._recall_at_precision(probs, labels, 0.90)\n",
    "        f1_macro_05 = self._f1_macro_at_threshold(probs, labels, 0.5)\n",
    "\n",
    "        print(\n",
    "            f\"[VAL] base_rate={base_rate:.6f}  AUPRC={float(val_auprc):.4f}  AUROC={float(val_auroc):.4f}  \"\n",
    "            f\"RPrec={rprec:.4f}  BestF1={best_f1:.4f} @thr={best_thr:.4f}  \"\n",
    "            f\"F1-macro@0.5={f1_macro_05:.4f}  Rec@P>=0.90={rec_at_p90:.4f}  \"\n",
    "            f\"Conf(TP/FP/TN/FN)={tp}/{fp}/{tn}/{fn}\"\n",
    "        )\n",
    "\n",
    "        self.log_dict({\n",
    "            \"val_acc\": val_acc, \"val_auprc\": val_auprc, \"val_auroc\": val_auroc,\n",
    "            \"val_pos_rate\": torch.as_tensor(base_rate, device=self.device),\n",
    "            \"val_random_auprc\": torch.as_tensor(base_rate, device=self.device),\n",
    "            \"val_rprecision\": torch.as_tensor(rprec, device=self.device),\n",
    "            \"val_precision_at_M\": torch.as_tensor(prec_m, device=self.device),\n",
    "            \"val_recall_at_M\": torch.as_tensor(rec_m, device=self.device),\n",
    "            \"val_precision_at_2M\": torch.as_tensor(prec_2m, device=self.device),\n",
    "            \"val_recall_at_2M\": torch.as_tensor(rec_2m, device=self.device),\n",
    "            \"val_precision_at_5M\": torch.as_tensor(prec_5m, device=self.device),\n",
    "            \"val_recall_at_5M\": torch.as_tensor(rec_5m, device=self.device),\n",
    "            \"val_best_f1\": torch.as_tensor(best_f1, device=self.device),\n",
    "            \"val_best_f1_threshold\": torch.as_tensor(best_thr, device=self.device),\n",
    "            \"val_macro_f1@0.5\": torch.as_tensor(f1_macro_05, device=self.device),\n",
    "            \"val_recall_at_precision_0.90\": torch.as_tensor(rec_at_p90, device=self.device),\n",
    "            \"val_tp_bestf1\": torch.as_tensor(tp, device=self.device),\n",
    "            \"val_fp_bestf1\": torch.as_tensor(fp, device=self.device),\n",
    "            \"val_tn_bestf1\": torch.as_tensor(tn, device=self.device),\n",
    "            \"val_fn_bestf1\": torch.as_tensor(fn, device=self.device),\n",
    "        }, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        self.val_acc.reset(); self.val_auprc.reset(); self.val_auroc.reset()\n",
    "        self._val_probs.clear(); self._val_labels.clear()\n",
    "\n",
    "    def on_test_epoch_start(self):\n",
    "        self._test_probs.clear(); self._test_labels.clear()\n",
    "\n",
    "    def test_step(self, batch, _):\n",
    "        x, y = batch\n",
    "        logits = self(x); probs = torch.sigmoid(logits.float())\n",
    "        self.test_acc.update(probs, y); self.test_auprc.update(probs, y); self.test_auroc.update(probs, y)\n",
    "        self._test_probs.append(_cpu(probs)); self._test_labels.append(_cpu(y).int())\n",
    "        self.log(\"test_loss\", self._bce_unweighted(logits, y), on_step=False, on_epoch=True)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        probs = torch.cat(self._test_probs, dim=0) if self._test_probs else torch.empty(0)\n",
    "        labels = torch.cat(self._test_labels, dim=0) if self._test_labels else torch.empty(0, dtype=torch.int64)\n",
    "        base_rate = float(labels.float().mean().item()) if labels.numel() > 0 else 0.0\n",
    "        both_classes = (labels.sum().item() > 0) and (labels.sum().item() < labels.numel())\n",
    "        try: test_auprc = self.test_auprc.compute()\n",
    "        except Exception: test_auprc = torch.as_tensor(base_rate, device=self.device)\n",
    "        try: test_auroc = self.test_auroc.compute() if both_classes else torch.as_tensor(0.5, device=self.device)\n",
    "        except Exception: test_auroc = torch.as_tensor(0.5, device=self.device)\n",
    "\n",
    "        rprec = self._rprecision(probs, labels)\n",
    "        m = int(labels.sum().item()) if labels.numel() > 0 else 1\n",
    "        prec_m, rec_m = self._precision_recall_at_k(probs, labels, max(1, m))\n",
    "        best_f1, best_thr, (tp, fp, tn, fn) = self._best_f1(probs, labels)\n",
    "        rec_at_p90 = self._recall_at_precision(probs, labels, 0.90)\n",
    "        f1_macro_05 = self._f1_macro_at_threshold(probs, labels, 0.5)\n",
    "\n",
    "        print(\n",
    "            f\"[TEST] base_rate={base_rate:.6f}  AUPRC={float(test_auprc):.4f}  AUROC={float(test_auroc):.4f}  \"\n",
    "            f\"RPrec={rprec:.4f}  BestF1={best_f1:.4f} @thr={best_thr:.4f}  \"\n",
    "            f\"F1-macro@0.5={f1_macro_05:.4f}  Rec@P>=0.90={rec_at_p90:.4f}  \"\n",
    "            f\"Conf(TP/FP/TN/FN)={tp}/{fp}/{tn}/{fn}\"\n",
    "        )\n",
    "\n",
    "        self.log_dict({\n",
    "            \"test_acc\": self.test_acc.compute(), \"test_auprc\": test_auprc, \"test_auroc\": test_auroc,\n",
    "            \"test_rprecision\": torch.as_tensor(rprec, device=self.device),\n",
    "            \"test_precision_at_M\": torch.as_tensor(prec_m, device=self.device),\n",
    "            \"test_recall_at_M\": torch.as_tensor(rec_m, device=self.device),\n",
    "            \"test_best_f1\": torch.as_tensor(best_f1, device=self.device),\n",
    "            \"test_best_f1_threshold\": torch.as_tensor(best_thr, device=self.device),\n",
    "            \"test_f1_macro@0.5\": torch.as_tensor(f1_macro_05, device=self.device),\n",
    "            \"test_recall_at_precision_0.90\": torch.as_tensor(rec_at_p90, device=self.device),\n",
    "        }, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        # Save predictions as CSV (index, label, probability)\n",
    "        try:\n",
    "            os.makedirs(\"playground\", exist_ok=True)\n",
    "            out_path = os.path.join(\"playground\", \"test_predictions.csv\")\n",
    "            with open(out_path, \"w\", newline=\"\") as f:\n",
    "                w = csv.writer(f); w.writerow([\"index\", \"label\", \"probability\"])\n",
    "                for i, (p, y) in enumerate(zip(probs.tolist(), labels.tolist())):\n",
    "                    w.writerow([i, int(y), float(p)])\n",
    "            print(f\"Saved test predictions to {out_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to save test predictions CSV: {e}\")\n",
    "\n",
    "        self.test_acc.reset(); self.test_auprc.reset(); self.test_auroc.reset()\n",
    "        self._test_probs.clear(); self._test_labels.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.AdamW(self.parameters(), lr=self.hparams.opt.lr, weight_decay=self.hparams.opt.weight_decay)\n",
    "        total_epochs = getattr(self.trainer, \"max_epochs\", 30) or 30\n",
    "        warm = max(0, int(self.hparams.opt.warmup_epochs))\n",
    "        if self.hparams.opt.cosine_after_warmup:\n",
    "            def lr_lambda(epoch):\n",
    "                if epoch < warm: return (epoch + 1) / max(1, warm)\n",
    "                t = (epoch - warm) / max(1, total_epochs - warm)\n",
    "                return 0.5 * (1 + math.cos(math.pi * t))\n",
    "            return {\"optimizer\": opt, \"lr_scheduler\": {\"scheduler\": torch.optim.lr_scheduler.LambdaLR(opt, lr_lambda)}}\n",
    "        sch = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"max\", factor=0.5, patience=2)\n",
    "        return {\"optimizer\": opt, \"lr_scheduler\": {\"scheduler\": sch, \"monitor\": \"val_auprc\"}}\n",
    "\n",
    "# ---------------- Data ----------------\n",
    "from pnpl.datasets.libribrain2025.word_dataset import LibriBrainWord\n",
    "from pnpl.datasets.libribrain2025.constants import RUN_KEYS\n",
    "try:\n",
    "    from pnpl.datasets.libribrain2025.base import LibriBrainBase\n",
    "except Exception:\n",
    "    LibriBrainBase = None\n",
    "\n",
    "class BalancedBatchSampler(BatchSampler):\n",
    "    \"\"\"Oversample positives to reach target fraction per batch (with replacement).\"\"\"\n",
    "    def __init__(self, pos_idx: List[int], neg_idx: List[int], batch_size: int, pos_fraction: float = 0.1):\n",
    "        assert 0.0 < pos_fraction < 1.0 and len(pos_idx) > 0\n",
    "        self.p_idx, self.n_idx = pos_idx, neg_idx\n",
    "        self.batch_size = batch_size\n",
    "        self.n_pos = max(1, int(round(batch_size * pos_fraction)))\n",
    "        self.n_neg = batch_size - self.n_pos\n",
    "        total = len(pos_idx) + len(neg_idx)\n",
    "        self._epoch_len = max(1, total // batch_size)\n",
    "\n",
    "    def __iter__(self) -> Iterator[List[int]]:\n",
    "        p, n = self.p_idx[:], self.n_idx[:]; random.shuffle(p); random.shuffle(n); pi = ni = 0\n",
    "        while True:\n",
    "            if pi + self.n_pos > len(p): random.shuffle(p); pi = 0\n",
    "            if ni + self.n_neg > len(n): random.shuffle(n); ni = 0\n",
    "            batch = p[pi:pi+self.n_pos] + n[ni:ni+self.n_neg]; pi += self.n_pos; ni += self.n_neg\n",
    "            random.shuffle(batch); yield batch\n",
    "\n",
    "    def __len__(self) -> int: return self._epoch_len\n",
    "\n",
    "class LibriBrainWordDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_path: str, tmin: float=-0.1, tmax: float=0.8, batch_size: int=256,\n",
    "                 num_workers: int=4, pin_memory: bool=True, standardize_train: bool=True,\n",
    "                 target_pos_fraction: float = 0.10,\n",
    "                 val_run_override: Optional[Tuple[str,str,str,str]] = None,\n",
    "                 test_run_override: Optional[Tuple[str,str,str,str]] = None):\n",
    "        super().__init__()\n",
    "        self.data_path, self.tmin, self.tmax = data_path, tmin, tmax\n",
    "        self.batch_size, self.num_workers, self.pin_memory = batch_size, num_workers, pin_memory\n",
    "        self.standardize_train = standardize_train\n",
    "        self.target_pos_fraction = target_pos_fraction\n",
    "        self.val_run_override = val_run_override; self.test_run_override = test_run_override\n",
    "        self._train_sampler: Optional[BalancedBatchSampler] = None\n",
    "\n",
    "    def _available_runs(self):\n",
    "        cands = [rk for rk in RUN_KEYS if rk[2].startswith('Sherlock')]\n",
    "        if LibriBrainBase is None: return cands\n",
    "        def _events_path(su, se, ta, ru):\n",
    "            return os.path.join(self.data_path, ta, \"derivatives\", \"events\",\n",
    "                                f\"sub-{su}_ses-{se}_task-{ta}_run-{ru}_events.tsv\")\n",
    "        def _h5_path(su, se, ta, ru):\n",
    "            return os.path.join(self.data_path, ta, \"derivatives\", \"serialised\",\n",
    "                                f\"sub-{su}_ses-{se}_task-{ta}_run-{ru}_proc-bads+headpos+sss+notch+bp+ds_meg.h5\")\n",
    "        avail=[]\n",
    "        for s,se,t,r in cands:\n",
    "            try:\n",
    "                LibriBrainBase.ensure_file_download(_events_path(s,se,t,r), data_path=self.data_path)\n",
    "                LibriBrainBase.ensure_file_download(_h5_path(s,se,t,r), data_path=self.data_path)\n",
    "                avail.append((s,se,t,r))\n",
    "            except Exception:\n",
    "                pass\n",
    "        return avail or cands\n",
    "\n",
    "    def _hash_key(self, train_runs: List[Tuple[str,str,str,str]]) -> str:\n",
    "        m = hashlib.sha256()\n",
    "        m.update(json.dumps({\"tmin\": self.tmin, \"tmax\": self.tmax,\n",
    "                             \"runs\": sorted([\"_\".join(x) for x in train_runs])},\n",
    "                            sort_keys=True).encode(\"utf-8\"))\n",
    "        return m.hexdigest()[:16]\n",
    "\n",
    "    def _cache_paths(self, key: str):  # single file for pos/neg index cache\n",
    "        cache_dir = os.path.join(self.data_path, \"_indices\"); os.makedirs(cache_dir, exist_ok=True)\n",
    "        return os.path.join(cache_dir, f\"watson_{key}.pt\")\n",
    "\n",
    "    def _try_dataset_labels_fast(self, ds: Dataset) -> Optional[List[int]]:\n",
    "        for attr in (\"labels\", \"y\", \"targets\", \"_labels\", \"_y\", \"_targets\"):\n",
    "            if hasattr(ds, attr):\n",
    "                lab = getattr(ds, attr)\n",
    "                try:\n",
    "                    if torch.is_tensor(lab): return lab.view(-1).cpu().int().tolist()\n",
    "                    return list(map(int, list(lab)))\n",
    "                except Exception: continue\n",
    "        return None\n",
    "\n",
    "    def _build_pos_neg_indices(self, ds: Dataset, cache_file: str) -> Tuple[List[int], List[int]]:\n",
    "        if os.path.exists(cache_file):\n",
    "            obj = torch.load(cache_file, map_location=\"cpu\")\n",
    "            pos_idx = list(map(int, obj[\"pos_idx\"])); neg_idx = list(map(int, obj[\"neg_idx\"]))\n",
    "            print(f\"Index cache: loaded {len(pos_idx)} positives / {len(pos_idx)+len(neg_idx)} total.\")\n",
    "            return pos_idx, neg_idx\n",
    "\n",
    "        lbls = self._try_dataset_labels_fast(ds)\n",
    "        if lbls is not None:\n",
    "            pos_idx = [i for i, y in enumerate(lbls) if int(y) == 1]\n",
    "            neg_idx = [i for i, y in enumerate(lbls) if int(y) == 0]\n",
    "            print(f\"Index fast-path: found {len(pos_idx)} positives / {len(lbls)} total.\")\n",
    "            torch.save({\"pos_idx\": pos_idx, \"neg_idx\": neg_idx}, cache_file)\n",
    "            return pos_idx, neg_idx\n",
    "\n",
    "        def _scan(num_workers: int) -> Tuple[List[int], List[int]]:\n",
    "            print(f\"Scanning training labels to build balanced sampler (num_workers={num_workers})…\")\n",
    "            pos_idx, neg_idx, idx = [], [], 0\n",
    "            loader = DataLoader(ds, batch_size=2048, shuffle=False,\n",
    "                                num_workers=num_workers, pin_memory=False,\n",
    "                                persistent_workers=(num_workers > 0),\n",
    "                                prefetch_factor=2 if num_workers > 0 else None,\n",
    "                                collate_fn=collate_label_only_xy)\n",
    "            for ys in loader:\n",
    "                for y in ys:\n",
    "                    (pos_idx if y == 1 else neg_idx).append(idx); idx += 1\n",
    "                if idx % 50000 == 0: print(f\"… scanned {idx} samples\")\n",
    "            return pos_idx, neg_idx\n",
    "\n",
    "        try: pos_idx, neg_idx = _scan(self.num_workers)\n",
    "        except Exception as e:\n",
    "            print(f\"[Label scan] parallel scan failed ({type(e).__name__}: {e}). Falling back to single-process.\")\n",
    "            pos_idx, neg_idx = _scan(0)\n",
    "\n",
    "        total = len(pos_idx) + len(neg_idx); frac = len(pos_idx) / max(1, total)\n",
    "        print(f\"Found {len(pos_idx)} positives / {total} total ({frac:.6f}).\")\n",
    "        torch.save({\"pos_idx\": pos_idx, \"neg_idx\": neg_idx}, cache_file)\n",
    "        return pos_idx, neg_idx\n",
    "\n",
    "    def setup(self, stage: Optional[str]=None):\n",
    "        all_runs = [rk for rk in self._available_runs()]\n",
    "        self.val_run  = self.val_run_override  or ('0','12','Sherlock4','1')\n",
    "        self.test_run = self.test_run_override or ('0','12','Sherlock5','1')\n",
    "        train_runs = [rk for rk in all_runs if rk not in (self.val_run, self.test_run)]\n",
    "\n",
    "        self.train_ds = LibriBrainWord(self.data_path, partition=\"train\",\n",
    "                                       keyword_detection=\"watson\",\n",
    "                                       preload_files=False,\n",
    "                                       include_info=False,\n",
    "                                       positive_buffer=0.25,\n",
    "                                       standardize=self.standardize_train)\n",
    "        self.val_ds   = LibriBrainWord(self.data_path, partition=\"validation\",\n",
    "                                       keyword_detection=\"watson\",\n",
    "                                       preload_files=False,\n",
    "                                       include_info=False,\n",
    "                                       standardize=True,\n",
    "                                       positive_buffer=0.25,\n",
    "                                       channel_means=getattr(self.train_ds, \"channel_means\", None),\n",
    "                                       channel_stds=getattr(self.train_ds, \"channel_stds\", None)\n",
    "                                      )\n",
    "        self.test_ds  = LibriBrainWord(self.data_path, partition=\"test\",\n",
    "                                       keyword_detection=\"watson\",\n",
    "                                       preload_files=False,\n",
    "                                       include_info=False,\n",
    "                                       standardize=True,\n",
    "                                       positive_buffer=0.25,\n",
    "                                       channel_means=getattr(self.train_ds, \"channel_means\", None),\n",
    "                                       channel_stds=getattr(self.train_ds, \"channel_stds\", None)\n",
    "                                      )\n",
    "\n",
    "        key = self._hash_key(train_runs); cache_file = self._cache_paths(key)\n",
    "        pos_idx, neg_idx = self._build_pos_neg_indices(self.train_ds, cache_file)\n",
    "        if len(pos_idx) == 0:\n",
    "            raise RuntimeError(\"No positive samples found in training set; cannot build balanced sampler.\")\n",
    "        self._pos_idx, self._neg_idx = pos_idx, neg_idx\n",
    "        self._train_sampler = BalancedBatchSampler(pos_idx, neg_idx, batch_size=self.batch_size,\n",
    "                                                   pos_fraction=self.target_pos_fraction)\n",
    "\n",
    "    def estimate_label_stats(self, sample: int = 200_000) -> Tuple[int,int]:\n",
    "        if hasattr(self, \"_pos_idx\") and hasattr(self, \"_neg_idx\"):\n",
    "            pos, total = len(self._pos_idx), len(self._pos_idx) + len(self._neg_idx)\n",
    "            if sample < total and total > 0:\n",
    "                frac = sample / total; pos = max(1, int(round(pos * frac))); total = sample\n",
    "            return pos, total\n",
    "        n = len(self.train_ds); k = min(20_000, n)\n",
    "        idxs = random.sample(range(n), k=k)\n",
    "        pos = sum(int(self.train_ds[i][1]) for i in idxs)\n",
    "        return pos, k\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_ds, batch_sampler=self._train_sampler,\n",
    "                          num_workers=self.num_workers, pin_memory=self.pin_memory,\n",
    "                          persistent_workers=(self.num_workers > 0),\n",
    "                          prefetch_factor=2 if self.num_workers > 0 else None)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_ds, batch_size=self.batch_size, shuffle=False,\n",
    "                          num_workers=self.num_workers, pin_memory=self.pin_memory,\n",
    "                          persistent_workers=(self.num_workers > 0),\n",
    "                          prefetch_factor=2 if self.num_workers > 0 else None)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_ds, batch_size=self.batch_size, shuffle=False,\n",
    "                          num_workers=self.num_workers, pin_memory=self.pin_memory,\n",
    "                          persistent_workers=(self.num_workers > 0),\n",
    "                          prefetch_factor=2 if self.num_workers > 0 else None)\n",
    "\n",
    "# ---------------- Train ----------------\n",
    "def main():\n",
    "    data_path   = \"dataset\"\n",
    "    tmin, tmax  = 0, 0.85\n",
    "    epochs      = 30\n",
    "    batch_size  = 256\n",
    "    lr          = 1e-4\n",
    "    num_workers = AUTO_WORKERS\n",
    "    precision = choose_precision()\n",
    "    devices     = 1\n",
    "    target_pos_fraction = 0.05\n",
    "    lse_temperature     = 0.5\n",
    "\n",
    "    VAL_RUN  = ('0','12','Sherlock4','1')\n",
    "    TEST_RUN = ('0','12','Sherlock5','1')\n",
    "\n",
    "    pl.seed_everything(42, workers=True)\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "\n",
    "    dm = LibriBrainWordDataModule(\n",
    "        data_path, tmin, tmax, batch_size, num_workers,\n",
    "        standardize_train=True, target_pos_fraction=target_pos_fraction\n",
    "    )\n",
    "    dm.setup()\n",
    "\n",
    "    pos, total = dm.estimate_label_stats(sample=200_000)\n",
    "    base_rate = pos / total\n",
    "    pos_weight = 1.0  # oversampling-only\n",
    "    print(f\"[Label stats] pos={pos} total={total}  π={base_rate:.6f}  \"\n",
    "          f\"target_p={target_pos_fraction:.2f}  pos_weight_eff={pos_weight:.1f}\")\n",
    "    print(f\"[Config] window=({tmin:.2f},{tmax:.2f})  sampler_pos={target_pos_fraction:.2f}  \"\n",
    "          f\"loss=focal(0.95,2.0)+pairwise(0.5)  pooling=attention\")\n",
    "\n",
    "    neptune_logger = make_neptune_logger(run_name=\"watson-meg\")\n",
    "    if neptune_logger:\n",
    "        neptune_logger.log_hyperparams({\n",
    "            \"data_path\": data_path, \"tmin\": tmin, \"tmax\": tmax,\n",
    "            \"batch_size\": batch_size, \"lr\": lr, \"precision\": precision,\n",
    "            \"base_rate\": base_rate, \"target_pos_fraction\": target_pos_fraction,\n",
    "            \"loss\": \"focal(alpha=0.95,gamma=2.0)+pairwise(lambda=0.5)\", \"pooling\": \"temporal_attention\",\n",
    "            \"pos_weight_eff\": pos_weight,\n",
    "            \"val_run\": \"_\".join(VAL_RUN), \"test_run\": \"_\".join(TEST_RUN),\n",
    "            \"schedule\": \"warmup+cosine\",\n",
    "        })\n",
    "\n",
    "    model = WatsonKeywordPL(\n",
    "        in_channels=306, pos_weight=pos_weight,\n",
    "        opt=OptimConfig(lr=lr, weight_decay=1e-4, max_time_shift=4, noise_std=0.01,\n",
    "                        warmup_epochs=1, cosine_after_warmup=True),\n",
    "        lse_temperature=lse_temperature\n",
    "    )\n",
    "\n",
    "    ckpt_cb = ModelCheckpoint(monitor=\"val_auprc\", mode=\"max\", save_top_k=1, filename=\"best-val-auprc\")\n",
    "    callbacks = [ckpt_cb, EarlyStopping(monitor=\"val_auprc\", mode=\"max\", patience=6, min_delta=5e-4),\n",
    "                 LearningRateMonitor(logging_interval=\"epoch\")]\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=epochs, precision=precision, devices=devices,\n",
    "        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "        callbacks=callbacks, logger=neptune_logger,\n",
    "        log_every_n_steps=25, gradient_clip_val=1.0,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, datamodule=dm)\n",
    "\n",
    "    if neptune_logger and ckpt_cb.best_model_path:\n",
    "        try:\n",
    "            neptune_logger.experiment[\"artifacts/checkpoints/best\"].upload(ckpt_cb.best_model_path)\n",
    "            print(f\"Neptune: uploaded best checkpoint -> {ckpt_cb.best_model_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Neptune: failed to upload checkpoint: {e}\")\n",
    "\n",
    "    trainer.test(model, datamodule=dm)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbc2505-b82c-4940-92c6-f24c5f6f6a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Speed knobs (precision + dataloader tuning + TF32)\n",
    "import os, time, itertools\n",
    "import torch\n",
    "\n",
    "def choose_precision():\n",
    "    if not torch.cuda.is_available():\n",
    "        return \"32-true\"\n",
    "    # Prefer BF16 if natively supported; otherwise use FP16 mixed\n",
    "    if torch.cuda.is_bf16_supported():\n",
    "        return \"bf16-mixed\"\n",
    "    return \"16-mixed\"\n",
    "\n",
    "# Enable fast paths on Ampere+/Ada (safe for training here)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "USE_COMPILE = False  # Potentially useful - we didn't use it in our experiments.\n",
    "\n",
    "def maybe_compile(model: torch.nn.Module) -> torch.nn.Module:\n",
    "    if USE_COMPILE and torch.cuda.is_available() and hasattr(torch, \"compile\"):\n",
    "        try:\n",
    "            return torch.compile(model, mode=\"max-autotune\")\n",
    "        except Exception as e:\n",
    "            print(f\"[compile] fallback (disabled): {e}\")\n",
    "            return model\n",
    "    return model\n",
    "\n",
    "# Better dataloader defaults (don’t modify base DM; monkey-patch loader kwargs)\n",
    "DLOADER_KW = {\n",
    "    \"pin_memory\": torch.cuda.is_available(),\n",
    "    \"persistent_workers\": True,   # keep workers alive across epochs\n",
    "    \"prefetch_factor\": 4,         # * workers queued batches\n",
    "}\n",
    "\n",
    "# heuristics for workers: saturate but don’t nuke the box\n",
    "CPU_COUNT = os.cpu_count() or 8\n",
    "AUTO_WORKERS = max(4, min(14, CPU_COUNT // 2))\n",
    "print(\"Num Workers: \", AUTO_WORKERS)\n",
    "\n",
    "# --- tiny probe to see if you’re data-bound (optional) ---\n",
    "def dataloader_probe(dm, max_batches=50):\n",
    "    \"\"\"Measure samples/sec of the train loader without running a full epoch.\"\"\"\n",
    "    try:\n",
    "        dl = dm.train_dataloader()\n",
    "        it = iter(dl)\n",
    "        # warmup a couple of batches (to start workers)\n",
    "        for _ in range(3):\n",
    "            next(it)\n",
    "        t0 = time.time()\n",
    "        seen = 0\n",
    "        for _ in range(max_batches):\n",
    "            batch = next(it)\n",
    "            x = batch[0] if isinstance(batch, (tuple, list)) else batch\n",
    "            bs = x.shape[0] if hasattr(x, \"shape\") else 1\n",
    "            seen += bs\n",
    "        dt = time.time() - t0\n",
    "        print(f\"[probe] ~{seen/max(1,dt):.1f} samples/sec over {max_batches} batches\")\n",
    "    except StopIteration:\n",
    "        print(\"[probe] train loader exhausted quickly; increase max_batches to measure.\")\n",
    "    except Exception as e:\n",
    "        print(f\"[probe] probe skipped: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2b1ffb-e4ef-44f6-a1b0-d9c65ff6497c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %% Buffer-length sweep — impact of positive_buffer & negative_buffer\n",
    "# Logs + artifacts: playground/buffer/neg=XX_pos=YY/seedZ/\n",
    "import os, csv, json, shutil, gc, random, hashlib, glob\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor, EarlyStopping\n",
    "\n",
    "# Reuse from previous cells:\n",
    "# - WatsonKeywordPL, OptimConfig, BalancedBatchSampler\n",
    "# - LibriBrainWordDataModule base class and LibriBrainWord / RUN_KEYS / LibriBrainBase imports\n",
    "\n",
    "# ----------------- config -----------------\n",
    "NEG_BUFFERS = [0.00, 0.05, 0.10, 0.15, 0.20]\n",
    "POS_BUFFERS = [0.00, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30]\n",
    "SEEDS       = [1, 2, 3]\n",
    "\n",
    "BASE_DIR = os.path.join(\"playground\", \"buffer\")\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "\n",
    "# ----------------- DataModule subclass with buffer control -----------------\n",
    "class BufferSweepDM(LibriBrainWordDataModule):\n",
    "    def __init__(self, data_path: str, tmin: float, tmax: float, batch_size: int, num_workers: int,\n",
    "                 target_pos_fraction: float, pos_buf: float, neg_buf: float,\n",
    "                 pin_memory: bool=True, standardize_train: bool=True,\n",
    "                 val_run_override: Optional[Tuple[str,str,str,str]] = None,\n",
    "                 test_run_override: Optional[Tuple[str,str,str,str]] = None):\n",
    "        super().__init__(data_path, tmin, tmax, batch_size, num_workers, pin_memory,\n",
    "                         standardize_train, target_pos_fraction, val_run_override, test_run_override)\n",
    "        self.pos_buf = float(pos_buf)\n",
    "        self.neg_buf = float(neg_buf)\n",
    "\n",
    "    # include buffers in index-cache key so we never reuse wrong label indices\n",
    "    def _hash_key(self, train_runs: List[Tuple[str,str,str,str]]) -> str:\n",
    "        m = hashlib.sha256()\n",
    "        m.update(json.dumps({\n",
    "            \"tmin\": self.tmin, \"tmax\": self.tmax,\n",
    "            \"pos_buf\": self.pos_buf, \"neg_buf\": self.neg_buf,\n",
    "            \"runs\": sorted([\"_\".join(x) for x in train_runs])\n",
    "        }, sort_keys=True).encode(\"utf-8\"))\n",
    "        return m.hexdigest()[:16]\n",
    "\n",
    "    def setup(self, stage: Optional[str]=None):\n",
    "        all_runs = [rk for rk in self._available_runs()]\n",
    "        self.val_run  = self.val_run_override  or ('0','12','Sherlock4','1')\n",
    "        self.test_run = self.test_run_override or ('0','12','Sherlock5','1')\n",
    "        train_runs = [rk for rk in all_runs if rk not in (self.val_run, self.test_run)]\n",
    "\n",
    "        # Build datasets with the requested buffers\n",
    "        self.train_ds = LibriBrainWord(self.data_path, partition=\"train\",\n",
    "                                       keyword_detection=\"watson\",\n",
    "                                       preload_files=False,\n",
    "                                       include_info=False,\n",
    "                                       positive_buffer=self.pos_buf,\n",
    "                                       negative_buffer=self.neg_buf,\n",
    "                                       standardize=self.standardize_train)\n",
    "        self.val_ds   = LibriBrainWord(self.data_path, partition=\"validation\",\n",
    "                                       keyword_detection=\"watson\",\n",
    "                                       preload_files=False,\n",
    "                                       include_info=False,\n",
    "                                       standardize=True,\n",
    "                                       positive_buffer=self.pos_buf,\n",
    "                                       negative_buffer=self.neg_buf,\n",
    "                                       channel_means=getattr(self.train_ds, \"channel_means\", None),\n",
    "                                       channel_stds=getattr(self.train_ds, \"channel_stds\", None))\n",
    "        self.test_ds  = LibriBrainWord(self.data_path, partition=\"test\",\n",
    "                                       keyword_detection=\"watson\",\n",
    "                                       preload_files=False,\n",
    "                                       include_info=False,\n",
    "                                       standardize=True,\n",
    "                                       positive_buffer=self.pos_buf,\n",
    "                                       negative_buffer=self.neg_buf,\n",
    "                                       channel_means=getattr(self.train_ds, \"channel_means\", None),\n",
    "                                       channel_stds=getattr(self.train_ds, \"channel_stds\", None))\n",
    "\n",
    "        key = self._hash_key(train_runs); cache_file = self._cache_paths(key)\n",
    "        pos_idx, neg_idx = self._build_pos_neg_indices(self.train_ds, cache_file)\n",
    "        if len(pos_idx) == 0:\n",
    "            raise RuntimeError(\"No positive samples found in training set; cannot build balanced sampler.\")\n",
    "\n",
    "        self._pos_idx, self._neg_idx = pos_idx, neg_idx\n",
    "        self._train_sampler = BalancedBatchSampler(pos_idx, neg_idx,\n",
    "                                                   batch_size=self.batch_size,\n",
    "                                                   pos_fraction=self.target_pos_fraction)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # sanity print per epoch\n",
    "        if isinstance(self._train_sampler, BalancedBatchSampler):\n",
    "            try: steps = len(self._train_sampler)\n",
    "            except Exception: steps = \"?\"\n",
    "            print(f\"[train loader] buffers: pos={self.pos_buf:.2f}, neg={self.neg_buf:.2f}  \"\n",
    "                  f\"|P|={len(self._train_sampler.p_idx)} |N|={len(self._train_sampler.n_idx)}  \"\n",
    "                  f\"pos_fraction={self.target_pos_fraction:.3f} batch={self.batch_size} steps/epoch={steps}\")\n",
    "        return super().train_dataloader()\n",
    "\n",
    "# ----------------- helpers -----------------\n",
    "def ensure_dir(p: str) -> str:\n",
    "    os.makedirs(p, exist_ok=True); return p\n",
    "\n",
    "def tag_float(x: float) -> str:\n",
    "    # e.g., 0.10 -> \"0p10\", 0.0 -> \"0p00\"\n",
    "    return f\"{x:.2f}\".replace(\".\", \"p\")\n",
    "\n",
    "def csv_nonempty(path: str, min_rows: int = 1) -> bool:\n",
    "    if not os.path.exists(path): return False\n",
    "    try:\n",
    "        with open(path, \"r\") as f:\n",
    "            r = csv.reader(f)\n",
    "            header = next(r, None)\n",
    "            if header is None: return False\n",
    "            for i, _ in enumerate(r, start=1):\n",
    "                if i >= min_rows:\n",
    "                    return True\n",
    "    except Exception:\n",
    "        return False\n",
    "    return False\n",
    "\n",
    "def seed_dir_path(dst_cfg_dir: str, seed: int) -> str:\n",
    "    return os.path.join(dst_cfg_dir, f\"seed{seed}\")\n",
    "\n",
    "def seed_preds_path(dst_cfg_dir: str, seed: int) -> str:\n",
    "    return os.path.join(seed_dir_path(dst_cfg_dir, seed), f\"test_predictions_seed{seed}.csv\")\n",
    "\n",
    "def seed_probs_path(dst_cfg_dir: str, seed: int) -> str:\n",
    "    return os.path.join(seed_dir_path(dst_cfg_dir, seed), f\"test_probs_seed{seed}.csv\")\n",
    "\n",
    "def labels_path(dst_cfg_dir: str) -> str:\n",
    "    return os.path.join(dst_cfg_dir, \"test_labels.csv\")\n",
    "\n",
    "def find_best_ckpt(seed_dir: str) -> Optional[str]:\n",
    "    # Matches ModelCheckpoint filename pattern used below\n",
    "    cands = sorted(glob.glob(os.path.join(seed_dir, \"best-val-auprc-s*/*.ckpt\")))  # PL sometimes nests by version\n",
    "    cands += sorted(glob.glob(os.path.join(seed_dir, \"best-val-auprc-s*.ckpt\")))\n",
    "    return cands[0] if cands else None\n",
    "\n",
    "def split_predictions_csv(src_csv: str, dst_seed_dir: str, dst_cfg_dir: str, seed: int):\n",
    "    \"\"\"Create per-seed probs and one labels file at the config level from a full predictions CSV.\"\"\"\n",
    "    indices, labels, probs = [], [], []\n",
    "    with open(src_csv, \"r\") as f:\n",
    "        r = csv.DictReader(f)\n",
    "        for row in r:\n",
    "            indices.append(int(row[\"index\"]))\n",
    "            labels.append(int(row[\"label\"]))\n",
    "            probs.append(float(row[\"probability\"]))\n",
    "\n",
    "    # probs per-seed\n",
    "    os.makedirs(dst_seed_dir, exist_ok=True)\n",
    "    with open(os.path.join(dst_seed_dir, f\"test_probs_seed{seed}.csv\"), \"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f); w.writerow([\"index\", \"probability\"])\n",
    "        for i, p in zip(indices, probs):\n",
    "            w.writerow([i, p])\n",
    "\n",
    "    # labels once per-config (+ convenience copy in seed1 dir)\n",
    "    if not os.path.exists(os.path.join(dst_cfg_dir, \"test_labels.csv\")):\n",
    "        with open(os.path.join(dst_cfg_dir, \"test_labels.csv\"), \"w\", newline=\"\") as f:\n",
    "            w = csv.writer(f); w.writerow([\"index\", \"label\"])\n",
    "            for i, y in zip(indices, labels):\n",
    "                w.writerow([i, y])\n",
    "        if seed == 1:\n",
    "            with open(os.path.join(dst_seed_dir, \"test_labels.csv\"), \"w\", newline=\"\") as f:\n",
    "                w = csv.writer(f); w.writerow([\"index\", \"label\"])\n",
    "                for i, y in zip(indices, labels):\n",
    "                    w.writerow([i, y])\n",
    "\n",
    "def write_combined_probs(dst_cfg_dir: str):\n",
    "    lab_path = labels_path(dst_cfg_dir)\n",
    "    if not os.path.exists(lab_path):\n",
    "        print(f\"[combine] labels not found for {dst_cfg_dir} — skipping\")\n",
    "        return\n",
    "    with open(lab_path, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        labels = [(int(r[\"index\"]), int(r[\"label\"])) for r in reader]\n",
    "\n",
    "    all_probs: Dict[int, Dict[int, float]] = {}\n",
    "    for s in SEEDS:\n",
    "        p_path = seed_probs_path(dst_cfg_dir, s)\n",
    "        if not os.path.exists(p_path):\n",
    "            print(f\"[combine] missing probs for seed{s} in {dst_cfg_dir} — skipping combine\")\n",
    "            return\n",
    "        with open(p_path, \"r\") as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            all_probs[s] = {int(r[\"index\"]): float(r[\"probability\"]) for r in reader}\n",
    "\n",
    "    combined_path = os.path.join(dst_cfg_dir, \"test_probs_all_seeds.csv\")\n",
    "    with open(combined_path, \"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"index\", \"label\", \"prob_seed1\", \"prob_seed2\", \"prob_seed3\"])\n",
    "        for idx, lab in labels:\n",
    "            w.writerow([\n",
    "                idx, lab,\n",
    "                all_probs[1].get(idx, float(\"nan\")),\n",
    "                all_probs[2].get(idx, float(\"nan\")),\n",
    "                all_probs[3].get(idx, float(\"nan\")),\n",
    "            ])\n",
    "    print(f\"[combine] wrote {combined_path}\")\n",
    "\n",
    "def record_metrics(row_path: str, row: Dict[str, float], header: List[str]):\n",
    "    exists = os.path.exists(row_path)\n",
    "    with open(row_path, \"a\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        if not exists:\n",
    "            w.writerow(header)\n",
    "        w.writerow([row.get(k, \"\") for k in header])\n",
    "\n",
    "def seed_artifacts_ok(dst_cfg_dir: str, seed: int) -> bool:\n",
    "    \"\"\"A seed is considered 'done' if its per-seed FULL predictions CSV exists & non-empty.\n",
    "       We'll backfill probs/labels if missing.\"\"\"\n",
    "    full_preds = seed_preds_path(dst_cfg_dir, seed)\n",
    "    return csv_nonempty(full_preds, min_rows=1)\n",
    "\n",
    "def backfill_splits_if_missing(dst_cfg_dir: str, seed: int):\n",
    "    \"\"\"If test_probs_seed{seed}.csv or test_labels.csv are missing, build them from the per-seed full predictions.\"\"\"\n",
    "    full_preds = seed_preds_path(dst_cfg_dir, seed)\n",
    "    if not os.path.exists(full_preds):  # nothing to do\n",
    "        return\n",
    "    need_probs = not os.path.exists(seed_probs_path(dst_cfg_dir, seed))\n",
    "    need_labels = not os.path.exists(labels_path(dst_cfg_dir))\n",
    "    if need_probs or need_labels:\n",
    "        print(f\"[seed {seed}] backfilling splits from {full_preds} \"\n",
    "              f\"(probs missing? {need_probs}, labels missing? {need_labels})\")\n",
    "        split_predictions_csv(full_preds, seed_dir_path(dst_cfg_dir, seed), dst_cfg_dir, seed)\n",
    "\n",
    "# ----------------- runner -----------------\n",
    "def run_one_config(pos_buf: float, neg_buf: float):\n",
    "    cfg_tag = f\"neg={tag_float(neg_buf)}_pos={tag_float(pos_buf)}\"\n",
    "    dst_cfg_dir = ensure_dir(os.path.join(BASE_DIR, cfg_tag))\n",
    "    summary_csv = os.path.join(dst_cfg_dir, \"metrics_summary.csv\")\n",
    "\n",
    "    print(f\"\\n================  Buffers: pos={pos_buf:.2f}  neg={neg_buf:.2f}  ================\\n\")\n",
    "    with open(os.path.join(dst_cfg_dir, \"manifest.json\"), \"w\") as f:\n",
    "        json.dump({\"positive_buffer\": pos_buf, \"negative_buffer\": neg_buf}, f, indent=2)\n",
    "\n",
    "    # quick short-circuit: if every seed has its full predictions, just backfill splits/combine and bail\n",
    "    all_done = True\n",
    "    for seed in SEEDS:\n",
    "        if not seed_artifacts_ok(dst_cfg_dir, seed):\n",
    "            all_done = False\n",
    "            break\n",
    "    if all_done:\n",
    "        print(f\"[skip] all seeds already complete for {cfg_tag}. Ensuring splits & combined...\")\n",
    "        for seed in SEEDS:\n",
    "            backfill_splits_if_missing(dst_cfg_dir, seed)\n",
    "        write_combined_probs(dst_cfg_dir)\n",
    "        return\n",
    "\n",
    "    for seed in SEEDS:\n",
    "        torch.cuda.empty_cache(); gc.collect()\n",
    "        seed_dir = ensure_dir(os.path.join(dst_cfg_dir, f\"seed{seed}\"))\n",
    "        print(f\"\\n--- seed {seed} ---\")\n",
    "\n",
    "        # If already done, just ensure splits exist and continue\n",
    "        if seed_artifacts_ok(dst_cfg_dir, seed):\n",
    "            print(f\"[skip] found existing predictions for seed {seed}: {seed_preds_path(dst_cfg_dir, seed)}\")\n",
    "            backfill_splits_if_missing(dst_cfg_dir, seed)\n",
    "            continue\n",
    "\n",
    "        data_path   = \"dataset\"\n",
    "        tmin, tmax  = 0.0, 0.85\n",
    "        epochs      = 30\n",
    "        batch_size  = 2048\n",
    "        lr          = 1e-4\n",
    "        num_workers = AUTO_WORKERS\n",
    "        precision   = \"bf16-mixed\"\n",
    "        devices     = 1\n",
    "        target_pos_fraction = 0.05\n",
    "        lse_temperature     = 0.5\n",
    "\n",
    "        pl.seed_everything(seed, workers=True)\n",
    "        torch.set_float32_matmul_precision('high')\n",
    "\n",
    "        dm = BufferSweepDM(\n",
    "            data_path=data_path, tmin=tmin, tmax=tmax, batch_size=batch_size, num_workers=num_workers,\n",
    "            target_pos_fraction=target_pos_fraction, pos_buf=pos_buf, neg_buf=neg_buf,\n",
    "            pin_memory=True, standardize_train=True\n",
    "        )\n",
    "        dm.setup()\n",
    "\n",
    "        # If there is already a best checkpoint, avoid retraining; just test from ckpt to regenerate predictions.\n",
    "        existing_best_ckpt = find_best_ckpt(seed_dir)\n",
    "        if existing_best_ckpt and not os.path.exists(seed_preds_path(dst_cfg_dir, seed)):\n",
    "            print(f\"[fast-path] best checkpoint found for seed {seed} -> test-only: {existing_best_ckpt}\")\n",
    "            trainer = pl.Trainer(\n",
    "                precision=precision,\n",
    "                devices=devices,\n",
    "                accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "                logger=None,\n",
    "                default_root_dir=seed_dir,\n",
    "                log_every_n_steps=25,\n",
    "            )\n",
    "            results = trainer.test(model=None, datamodule=dm, ckpt_path=existing_best_ckpt)\n",
    "            results = results[0] if isinstance(results, list) and results else {}\n",
    "        else:\n",
    "            # Full train + test\n",
    "            model = WatsonKeywordPL(\n",
    "                in_channels=306, pos_weight=1.0,\n",
    "                opt=OptimConfig(lr=lr, weight_decay=1e-4, max_time_shift=4, noise_std=0.01,\n",
    "                                warmup_epochs=1, cosine_after_warmup=True),\n",
    "                lse_temperature=lse_temperature\n",
    "            )\n",
    "\n",
    "            ckpt_cb = ModelCheckpoint(monitor=\"val_auprc\", mode=\"max\", save_top_k=1,\n",
    "                                      filename=f\"best-val-auprc-s{seed}\")\n",
    "            callbacks = [\n",
    "                ckpt_cb,\n",
    "                EarlyStopping(monitor=\"val_auprc\", mode=\"max\", patience=6, min_delta=5e-4),\n",
    "                LearningRateMonitor(logging_interval=\"epoch\"),\n",
    "            ]\n",
    "            trainer = pl.Trainer(\n",
    "                max_epochs=epochs,\n",
    "                precision=precision,\n",
    "                devices=devices,\n",
    "                accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "                callbacks=callbacks,\n",
    "                logger=None,\n",
    "                log_every_n_steps=25,\n",
    "                gradient_clip_val=1.0,\n",
    "                default_root_dir=seed_dir,\n",
    "            )\n",
    "\n",
    "            # train\n",
    "            trainer.fit(model, datamodule=dm)\n",
    "\n",
    "            # test with best checkpoint (module writes playground/test_predictions.csv)\n",
    "            ckpt_path = ckpt_cb.best_model_path if ckpt_cb.best_model_path else None\n",
    "            results = trainer.test(model=None, datamodule=dm, ckpt_path=ckpt_path)\n",
    "            results = results[0] if isinstance(results, list) and results else {}\n",
    "\n",
    "        # ---- save ALL prediction CSVs under playground/buffer/... ----\n",
    "        # Preferred source is the test_predictions.csv the module writes.\n",
    "        src_preds_global = os.path.join(\"playground\", \"test_predictions.csv\")\n",
    "        dst_seed_preds   = seed_preds_path(dst_cfg_dir, seed)\n",
    "\n",
    "        if os.path.exists(src_preds_global):\n",
    "            shutil.copy2(src_preds_global, dst_seed_preds)\n",
    "            print(f\"[seed {seed}] saved full predictions -> {dst_seed_preds}\")\n",
    "        elif not os.path.exists(dst_seed_preds):\n",
    "            # As a fallback, if the module didn't write to global path but PL wrote somewhere else,\n",
    "            # user can still place/rename it to dst_seed_preds and re-run just this backfill section.\n",
    "            print(f\"[seed {seed}] WARNING: expected predictions at {src_preds_global} not found \"\n",
    "                  f\"and no existing {dst_seed_preds}. Cannot backfill splits for this seed yet.\")\n",
    "\n",
    "        # Create per-seed probs + labels (once) beside it\n",
    "        if os.path.exists(dst_seed_preds):\n",
    "            split_predictions_csv(dst_seed_preds, seed_dir, dst_cfg_dir, seed)\n",
    "\n",
    "        # metrics row per seed (only if results are available in this run)\n",
    "        if results:\n",
    "            header = [\n",
    "                \"positive_buffer\", \"negative_buffer\", \"seed\",\n",
    "                \"test_acc\", \"test_auprc\", \"test_auroc\",\n",
    "                \"test_best_f1\", \"test_best_f1_threshold\",\n",
    "                \"test_rprecision\", \"test_precision_at_M\", \"test_recall_at_M\",\n",
    "                \"test_f1_macro@0.5\", \"test_recall_at_precision_0.90\",\n",
    "                \"train_pos_count\", \"train_neg_count\"\n",
    "            ]\n",
    "            row = {\n",
    "                \"positive_buffer\": pos_buf, \"negative_buffer\": neg_buf, \"seed\": seed,\n",
    "                \"test_acc\": results.get(\"test_acc\", \"\"),\n",
    "                \"test_auprc\": results.get(\"test_auprc\", \"\"),\n",
    "                \"test_auroc\": results.get(\"test_auroc\", \"\"),\n",
    "                \"test_best_f1\": results.get(\"test_best_f1\", \"\"),\n",
    "                \"test_best_f1_threshold\": results.get(\"test_best_f1_threshold\", \"\"),\n",
    "                \"test_rprecision\": results.get(\"test_rprecision\", \"\"),\n",
    "                \"test_precision_at_M\": results.get(\"test_precision_at_M\", \"\"),\n",
    "                \"test_recall_at_M\": results.get(\"test_recall_at_M\", \"\"),\n",
    "                \"test_f1_macro@0.5\": results.get(\"test_f1_macro@0.5\", \"\"),\n",
    "                \"test_recall_at_precision_0.90\": results.get(\"test_recall_at_precision_0.90\", \"\"),\n",
    "                \"train_pos_count\": len(getattr(dm, \"_pos_idx\", [])),\n",
    "                \"train_neg_count\": len(getattr(dm, \"_neg_idx\", [])),\n",
    "            }\n",
    "            record_metrics(summary_csv, row, header)\n",
    "\n",
    "        # cleanup\n",
    "        torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "    # combined probs for the config\n",
    "    # (works if all seeds now have probs + labels; otherwise prints a helpful skip note)\n",
    "    write_combined_probs(dst_cfg_dir)\n",
    "\n",
    "# ----------------- go! -----------------\n",
    "total = len(NEG_BUFFERS) * len(POS_BUFFERS)\n",
    "k = 0\n",
    "for nb in reversed(NEG_BUFFERS):        # A: NEG asc ...   B: NEG desc\n",
    "    for pb in reversed(POS_BUFFERS):    # A: POS asc ...   B: POS desc\n",
    "        k += 1\n",
    "        print(f\"[{k}/{total}] pos={pb:.2f}  neg={nb:.2f}\")\n",
    "        run_one_config(pos_buf=pb, neg_buf=nb)\n",
    "\n",
    "print(\"\\n✅ Done. All outputs are under:\", BASE_DIR)\n",
    "print(\"Each config folder contains: seed folders, full test_predictions per seed, per-seed probs, labels, combined probs, and a metrics_summary.csv (for runs done in this session).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
